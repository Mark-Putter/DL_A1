{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human action recognition ##\n",
    "By Mark Putter - s3945532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Create model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,\n",
    "            y=y_train,\n",
    "            epochs=50,\n",
    "            verbose=0,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load('fashion_mnist', with_info=True, as_supervised=True)\n",
    "fmnist_train, fmnist_test = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "i=1\n",
    "for image, label in fmnist_train.take(4):  # example is (image, label)\n",
    "  plt.subplot(1,4,i)\n",
    "  plt.imshow(np.squeeze(image))\n",
    "  i = i+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Preprocess the dataset\n",
    "def convert_types(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "  return image, label\n",
    "\n",
    "batch_size = 32\n",
    "fmnist_train = fmnist_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
    "fmnist_test = fmnist_test.map(convert_types).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in fmnist_train.take(3):  # example is (image, label)\n",
    "  print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class FMNISTModel(Model):\n",
    "  def __init__(self):\n",
    "      super(FMNISTModel, self).__init__()\n",
    "      self.conv1 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(28, 28, 1))\n",
    "      self.pool1 = MaxPooling2D((2, 2))\n",
    "      self.flatten = Flatten()\n",
    "      self.d1 = Dense(128, activation='relu')\n",
    "      self.drop = Dropout(0.2)\n",
    "      self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "      x = self.conv1(x)\n",
    "      x = self.pool1(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.d1(x)\n",
    "      x = self.drop(x)\n",
    "      return self.d2(x)\n",
    "\n",
    "model = FMNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(image, label):\n",
    "  predictions = model(image)\n",
    "  t_loss = loss_object(label, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  print(\"starting Epoch: \", epoch)\n",
    "  # iterate over all batches in the dataset\n",
    "  for image, label in fmnist_train:\n",
    "    train_step(image, label)\n",
    "\n",
    "  for test_image, test_label in fmnist_test:\n",
    "    test_step(test_image, test_label)\n",
    "\n",
    "  print('Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "\n",
    "  train_loss.reset_state()\n",
    "  test_loss.reset_state()\n",
    "  train_accuracy.reset_state()\n",
    "  test_accuracy.reset_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
